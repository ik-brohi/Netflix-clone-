"use strict";
var __read = (this && this.__read) || function (o, n) {
    var m = typeof Symbol === "function" && o[Symbol.iterator];
    if (!m) return o;
    var i = m.call(o), r, ar = [], e;
    try {
        while ((n === void 0 || n-- > 0) && !(r = i.next()).done) ar.push(r.value);
    }
    catch (error) { e = { error: error }; }
    finally {
        try {
            if (r && !r.done && (m = i["return"])) m.call(i);
        }
        finally { if (e) throw e.error; }
    }
    return ar;
};
var __spread = (this && this.__spread) || function () {
    for (var ar = [], i = 0; i < arguments.length; i++) ar = ar.concat(__read(arguments[i]));
    return ar;
};
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) result[k] = mod[k];
    result["default"] = mod;
    return result;
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
var tf = __importStar(require("@tensorflow/tfjs"));
var _ = __importStar(require("lodash"));
var Errors_1 = require("../utils/Errors");
var MathExtra_1 = __importDefault(require("../utils/MathExtra"));
var permutations_1 = require("../utils/permutations");
var tensors_1 = require("../utils/tensors");
var validation_1 = require("../utils/validation");
/**
 * Augment dataset with an additional dummy feature.
 * This is useful for fitting an intercept term with implementations which cannot otherwise fit it directly.
 *
 * @example
 * import { add_dummy_feature } from 'machinelearn/preprocessing';
 * const dummy = add_dummy_feature([[0, 1, 2], [1, 0, 3]]);
 * console.log(dummy); // returns: [ [ 1, 0, 1, 2 ], [ 1, 1, 0, 3 ] ]
 *
 * @param X - A matrix of data
 * @param value - Value to use for the dummy feature.
 */
function add_dummy_feature(X, value) {
    if (X === void 0) { X = null; }
    if (value === void 0) { value = 1.0; }
    if (Array.isArray(X) && X.length === 0) {
        throw new TypeError('X cannot be empty');
    }
    validation_1.validateMatrix2D(X);
    var tensorX = tf.tensor2d(X);
    var _a = __read(tensorX.shape, 1), nSamples = _a[0];
    var ones = tf.ones([nSamples, 1]);
    var sValue = tf.scalar(value);
    var multipledOnes = tf.mul(ones, sValue);
    var hStacked = tf.concat([multipledOnes, tensorX], 1);
    return tensors_1.reshape(Array.from(hStacked.dataSync()), hStacked.shape);
}
exports.add_dummy_feature = add_dummy_feature;
/**
 * Encode categorical integer features using a one-hot aka one-of-K scheme.
 *
 * The input to this transformer should be a matrix of integers, denoting the
 * values taken on by categorical (discrete) features. The output will be a sparse
 * matrix where each column corresponds to one possible value of one feature.
 * It is assumed that input features take on values in the range [0, n_values).
 *
 * This encoding is needed for feeding categorical data to many
 * scikit-learn estimators, notably linear models and SVMs with the standard kernels.
 *
 * Note: a one-hot encoding of y labels should use a LabelBinarizer instead.
 *
 * @example
 * const enc = new OneHotEncoder();
 * const planetList = [
 *  { planet: 'mars', isGasGiant: false, value: 10 },
 *  { planet: 'saturn', isGasGiant: true, value: 20 },
 *  { planet: 'jupiter', isGasGiant: true, value: 30 }
 * ];
 * const encodeInfo = enc.encode(planetList, {
 *  dataKeys: ['value', 'isGasGiant'],
 *  labelKeys: ['planet']
 * });
 * // encodeInfo.data -> [ [ -1, 0, 1, 0, 0 ], [ 0, 1, 0, 1, 0 ], [ 1, 1, 0, 0, 1 ] ]
 * const decodedInfo = enc.decode(encodeInfo.data, encodeInfo.decoders);
 * // gives you back the original value, which is `planetList`
 */
var OneHotEncoder = /** @class */ (function () {
    function OneHotEncoder() {
        /**
         * Calculating the sample standard deviation (vs population stddev).
         * @param lst
         * @param {number} mean
         * @returns {number}
         */
        this.calculateStd = function (lst, mean) {
            var deviations = _.map(lst, function (n) { return Math.pow(n - mean, 2); });
            return Math.pow(_.sum(deviations) / (lst.length - 1), 0.5);
        };
    }
    /**
     * encode data according to dataKeys and labelKeys
     *
     * @param data - list of records to encode
     * @param options
     */
    OneHotEncoder.prototype.encode = function (data, _a) {
        var _this = this;
        if (data === void 0) { data = null; }
        var _b = _a === void 0 ? {
            dataKeys: null,
            labelKeys: null,
        } : _a, 
        /**
         * Independent variables
         */
        _c = _b.dataKeys, 
        /**
         * Independent variables
         */
        dataKeys = _c === void 0 ? null : _c, 
        /**
         * Depdenent variables
         */
        _d = _b.labelKeys, 
        /**
         * Depdenent variables
         */
        labelKeys = _d === void 0 ? null : _d;
        var decoders = [];
        // shortcut to allow caller to default to "all non-label keys are data keys"
        var _dataKeys = dataKeys ? dataKeys : _.keys(data[0]);
        // validations
        if (_.size(data) < 1) {
            throw Errors_1.ValidationError('data cannot be empty!');
        }
        // data keys
        _.forEach(_dataKeys, function (dataKey) {
            // TODO: it's only checking data[0] -> It should also check all the others
            if (!_.has(data[0], dataKey)) {
                // TODO: Find the correct error to throw
                throw new Errors_1.ValidationKeyNotFoundError("Cannot find " + dataKey + " from data");
            }
        });
        // label keys
        _.forEach(labelKeys, function (labelKey) {
            // TODO: it's only checking data[0] -> It should also check all the others
            if (!_.has(data[0], labelKey)) {
                // TODO Find the correct error to throw
                throw new Errors_1.ValidationKeyNotFoundError("Cannot find " + labelKey + " from labels");
            }
        });
        // maybe a little too clever but also the simplest;
        // serialize every value for a given data key, then zip the results back up into a (possibly nested) array
        var transform = function (keys) {
            return _.zip.apply(_, __spread(_.map(keys, function (key) {
                var standardized = _this.standardizeField(key, data);
                var encoded = _.get(standardized, 'encoded');
                var decode = _.get(standardized, 'decode');
                if (encoded && decode) {
                    // TODO: We need to prefer immutable datastructure
                    decoders.push(decode);
                    return encoded;
                }
                // Otherwise just return values itself
                return standardized;
            })));
        };
        var features = transform(_dataKeys);
        var labels = transform(labelKeys);
        return {
            // zip the label data back into the feature data (to ensure label data is at the end)
            data: _.map(_.zip(features, labels), _.flattenDeep),
            decoders: decoders,
        };
    };
    /**
     * Decode the encoded data back into its original format
     */
    OneHotEncoder.prototype.decode = function (encoded, decoders) {
        var _this = this;
        return _.map(encoded, function (row) { return _this.decodeRow(row, decoders); });
    };
    /**
     * Decode an encoded row back into its original format
     * @param row
     * @param decoders
     * @returns {Object}
     */
    OneHotEncoder.prototype.decodeRow = function (row, decoders) {
        var i = 0;
        var numFieldsDecoded = 0;
        var record = {};
        var getStrVal = function (X, ix, decoder) {
            var data = X.slice(ix, ix + decoder.offset);
            return decoder.lookupTable[_.indexOf(data, 1)];
        };
        var getBoolVal = function (X, ix) { return !!X[ix]; };
        var getNumbVal = function (X, ix, decoder) {
            return decoder.std * X[ix] + decoder.mean;
        };
        while (i < row.length) {
            var decoder = decoders[numFieldsDecoded++];
            if (decoder.type === 'string') {
                record[decoder.key] = getStrVal(row, i, decoder);
            }
            else if (decoder.type === 'number') {
                record[decoder.key] = getNumbVal(row, i, decoder);
            }
            else if (decoder.type === 'boolean') {
                record[decoder.key] = getBoolVal(row, i);
            }
            else {
                record[decoder.key] = row[i];
            }
            // record[decoder.key] = getValue(row, i, decoder);
            i += decoder.offset ? decoder.offset : 1;
        }
        return record;
    };
    /**
     * Standardizing field
     * Example dataset:
     * [ { planet: 'mars', isGasGiant: false, value: 10 },
     * { planet: 'saturn', isGasGiant: true, value: 20 },
     * { planet: 'jupiter', isGasGiant: true, value: 30 } ]
     *
     * @param key: each key/feature such as planet, isGasGiant and value
     * @param data: the entire dataset
     * @returns {any}
     */
    OneHotEncoder.prototype.standardizeField = function (key, data) {
        var type = typeof data[0][key];
        var values = _.map(data, key);
        switch (type) {
            case 'string': {
                var result = this.buildStringOneHot(type, key, values);
                return {
                    decode: result.decode,
                    encoded: result.encoded,
                };
            }
            case 'number': {
                // Apply std to values if type is number
                // standardize: ((n - mean)/std)
                // TODO: add support for scaling to [0, 1]
                var result = this.buildNumberOneHot(type, key, values);
                return {
                    decode: result.decode,
                    encoded: result.encoded,
                };
            }
            case 'boolean': {
                // True == 1
                // False == 0
                var result = this.buildBooleanOneHot(type, key, values);
                return {
                    decode: result.decode,
                    encoded: result.encoded,
                };
            }
            default:
                return values;
        }
    };
    /**
     * One hot encode a number value
     *
     * @param type
     * @param key
     * @param values
     * @returns {{encoded: any[]; decode: {type: any; mean: number; std: number; key: any}}}
     */
    OneHotEncoder.prototype.buildNumberOneHot = function (type, key, values) {
        var mean = _.mean(values);
        var std = this.calculateStd(values, mean);
        return {
            decode: { type: type, mean: mean, std: std, key: key },
            encoded: _.map(values, function (value) { return (value - mean) / std; }),
        };
    };
    /**
     * One hot encode a boolean value
     *
     * Example usage:
     * boolEncoder.encode(true) => 1
     * boolEncoder.encode(false) => 0
     *
     * @param type
     * @param key
     * @param values
     * @returns {{encode}}
     */
    OneHotEncoder.prototype.buildBooleanOneHot = function (type, key, values) {
        return {
            decode: { type: type, key: key },
            encoded: _.map(values, function (value) { return (value ? 1 : 0); }),
        };
    };
    /**
     * One hot encode a string value
     *
     * Example for internal reference (unnecessary details for those just using this module)
     *
     * const encoder = buildOneHot(['RAIN', 'RAIN', 'SUN'])
     * // encoder == { encode: () => ... , lookupTable: ['RAIN', 'SUN'] }
     * encoder.encode('SUN')  // [0, 1]
     * encoder.encode('RAIN') // [1, 0]
     * encoder.encode('SUN')  // [1, 0]
     * // encoder.lookupTable can then be passed into this.decode to translate [0, 1] back into 'SUN'
     *
     * It's not ideal (ideally it would all just be done in-memory and we could return a "decode" closure,
     * but it needs to be serializable to plain old JSON.
     */
    OneHotEncoder.prototype.buildStringOneHot = function (type, key, values) {
        var lookup = {};
        var i = 0;
        var lookupTable = _.map(_.uniq(values), function (value) {
            _.set(lookup, value, i++);
            return value;
        });
        var encoded = _.map(values, function (value) {
            return _.range(0, i).map(function (pos) { return (_.get(lookup, value) === pos ? 1 : 0); });
        });
        return {
            decode: {
                key: key,
                lookupTable: lookupTable,
                offset: encoded[0].length,
                type: type,
            },
            encoded: encoded,
        };
    };
    return OneHotEncoder;
}());
exports.OneHotEncoder = OneHotEncoder;
/**
 * Transforms features by scaling each feature to a given range.
 *
 * This estimator scales and translates each feature individually such that it is in the given range on the training set, i.e. between zero and one.
 *
 * The transformation is given by:
 *
 * ```
 * X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))
 * X_scaled = X_std * (max - min) + min
 * ```
 *
 * where min, max = feature_range.
 *
 * This transformation is often used as an alternative to zero mean, unit variance scaling.
 *
 * @example
 * import { MinMaxScaler } from 'machinelearn/preprocessing';
 *
 * const minmaxScaler = new MinMaxScaler({ featureRange: [0, 1] });
 *
 * // Fitting an 1D matrix
 * minmaxScaler.fit([4, 5, 6]);
 * const result = minmaxScaler.transform([4, 5, 6]);
 * // result = [ 0, 0.5, 1 ]
 *
 * // Fitting a 2D matrix
 * const minmaxScaler2 = new MinMaxScaler({ featureRange: [0, 1] });
 * minmaxScaler2.fit([[1, 2, 3], [4, 5, 6]]);
 * const result2 = minmaxScaler2.transform([[1, 2, 3]]);
 * // result2 = [ [ 0, 0.2, 0.4000000000000001 ] ]
 *
 */
var MinMaxScaler = /** @class */ (function () {
    /**
     * @param featureRange - scaling range
     */
    function MinMaxScaler(_a) {
        var _b = (_a === void 0 ? {
            featureRange: [0, 1],
        } : _a).featureRange, featureRange = _b === void 0 ? [0, 1] : _b;
        this.featureRange = featureRange;
    }
    /**
     * Compute the minimum and maximum to be used for later scaling.
     * @param {number[]} X - Array or sparse-matrix data input
     */
    MinMaxScaler.prototype.fit = function (X) {
        if (X === void 0) { X = null; }
        if (!Array.isArray(X)) {
            throw new Errors_1.ValidationError('MinMaxScaler received a non-array input for X');
        }
        var rowMax = tf.tensor(X);
        var rowMin = tf.tensor(X);
        var xShape = tensors_1.inferShape(X);
        // If input is a Matrix...
        if (xShape.length === 0 || xShape[0] === 0) {
            throw new Errors_1.ValidationError('Cannot fit with an empty value');
        }
        else if (xShape.length === 2) {
            rowMax = tf.max(rowMax, 0);
            rowMin = tf.min(rowMin, 0);
        }
        this.dataMax = tf.max(rowMax).dataSync()[0];
        this.dataMin = tf.min(rowMin).dataSync()[0];
        this.featureMax = this.featureRange[1];
        this.featureMin = this.featureRange[0];
        this.dataRange = this.dataMax - this.dataMin;
        // We need different data range for multi-dimensional
        this.scale = (this.featureMax - this.featureMin) / this.dataRange;
        this.baseMin = this.featureMin - this.dataMin * this.scale;
    };
    /**
     * Fit to data, then transform it.
     * @param X - Original input vector
     */
    MinMaxScaler.prototype.fit_transform = function (X) {
        this.fit(X);
        return this.transform(X);
    };
    /**
     * Scaling features of X according to feature_range.
     * @param X - Original input vector
     */
    MinMaxScaler.prototype.transform = function (X) {
        var _this = this;
        if (X === void 0) { X = null; }
        // Transforms a single vector
        var transform_single = function (_X) {
            var X1 = _X.map(function (x) { return x * _this.scale; });
            return X1.map(function (x) { return x + _this.baseMin; });
        };
        var shapes = tensors_1.inferShape(X);
        if (shapes.length === 2) {
            return X.map(function (z) { return transform_single(z); });
        }
        else if (shapes.length === 1) {
            return transform_single(X);
        }
        else {
            throw new TypeError("The input shape " + JSON.stringify(shapes) + " cannot be transformed");
        }
    };
    /**
     * Undo the scaling of X according to feature_range.
     * @param {number[]} X - Scaled input vector
     */
    MinMaxScaler.prototype.inverse_transform = function (X) {
        var _this = this;
        if (X === void 0) { X = null; }
        validation_1.validateMatrix1D(X);
        var X1 = X.map(function (x) { return x - _this.baseMin; });
        return X1.map(function (x) { return x / _this.scale; });
    };
    return MinMaxScaler;
}());
exports.MinMaxScaler = MinMaxScaler;
/**
 * Binarizer transform your data using a binary threshold.
 * All values above the threshold are marked 1 and all equal to or below are marked as 0.
 *
 * It can also be used as a pre-processing step for estimators that consider
 * boolean random variables (e.g. modelled using the Bernoulli distribution in
 * a Bayesian setting).
 *
 * @example
 * import { Binarizer } from 'machinelearn/preprocessing';
 *
 * const binX = [[1, -1, 2], [2, 0, 0], [0, 1, -1]];
 * const binarizer = new Binarizer({ threshold: 0 });
 * const result = binarizer.transform(binX);
 * // [ [ 1, 0, 1 ], [ 1, 0, 0 ], [ 0, 1, 0 ] ]
 */
var Binarizer = /** @class */ (function () {
    /**
     *
     * @param {number} threshold - Feature values below or equal to this are replaced by 0, above it by 1.
     * @param {boolean} copy - Flag to clone the input value.
     */
    function Binarizer(_a) {
        var _b = _a === void 0 ? {
            // Default value on empty constructor
            copy: true,
            threshold: 0,
        } : _a, 
        // Each object param default value
        _c = _b.copy, 
        // Each object param default value
        copy = _c === void 0 ? true : _c, _d = _b.threshold, threshold = _d === void 0 ? 0 : _d;
        this.threshold = threshold;
        this.copy = copy;
    }
    /**
     * Currently fit does nothing
     * @param {any[]} X - Does nothing
     */
    Binarizer.prototype.fit = function (X) {
        if (X === void 0) { X = null; }
        if (Array.isArray(X) && X.length === 0) {
            throw new Errors_1.ValidationError('X should be an array and cannot be empty');
        }
        validation_1.validateMatrix2D(X);
        console.info("Currently Bianrizer's fit is designed to do nothing");
    };
    /**
     * Transforms matrix into binarized form
     * X = [[ 1., -1.,  2.],
     *      [ 2.,  0.,  0.],
     *      [ 0.,  1., -1.]]
     * becomes
     * array([[ 1.,  0.,  1.],
     *    [ 1.,  0.,  0.],
     *    [ 0.,  1.,  0.]])
     * @param {any[]} X - The data to binarize.
     */
    Binarizer.prototype.transform = function (X) {
        if (X === void 0) { X = null; }
        var _X = this.copy ? _.clone(X) : X;
        if (Array.isArray(_X) && _X.length === 0) {
            throw new Errors_1.ValidationError('X should be an array and cannot be empty');
        }
        validation_1.validateMatrix2D(_X);
        for (var row = 0; row < _.size(X); row++) {
            var rowValue = _.get(X, "[" + row + "]");
            for (var column = 0; column < _.size(rowValue); column++) {
                var item = _.get(X, "[" + row + "][" + column + "]");
                // Type checking item; It must be a number type
                if (!_.isNumber(item)) {
                    throw new Error("Value " + item + " is not a number");
                }
                // If current item is less than
                _X[row][column] = item <= this.threshold ? 0 : 1;
            }
        }
        return _X;
    };
    return Binarizer;
}());
exports.Binarizer = Binarizer;
/**
 * Generate polynomial and interaction features.
 *
 * Generate a new feature matrix consisting of all polynomial combinations of the features
 * with degree less than or equal to the specified degree. For example, if an input sample
 * is two dimensional and of the form [a, b], the degree-2 polynomial features are [1, a, b, a^2, ab, b^2].
 *
 * @example
 * import { PolynomialFeatures } from 'machinelearn/preprocessing';
 * const poly = new PolynomialFeatures();
 * const X = [[0, 1], [2, 3], [4, 5]];
 * poly.transform(X);
 * // Result:
 * // [ [ 1, 0, 1, 0, 0, 1 ],
 * // [ 1, 2, 3, 4, 6, 9 ],
 * // [ 1, 4, 5, 16, 20, 25 ] ]
 *
 */
var PolynomialFeatures = /** @class */ (function () {
    /**
     *
     * @param degree - The degree of the polynomial features. Default = 2.
     */
    function PolynomialFeatures(_a) {
        var _b = (_a === void 0 ? {
            degree: 2,
        } : _a).degree, degree = _b === void 0 ? 2 : _b;
        // Constructor variables validation
        if (!Number.isInteger(degree)) {
            throw new Errors_1.ConstructionError('Degree must be a number');
        }
        this.degree = degree;
    }
    /**
     * Transforms the input data
     * @param X - a matrix
     */
    PolynomialFeatures.prototype.transform = function (X) {
        if (X === void 0) { X = null; }
        if (Array.isArray(X) && X.length === 0) {
            throw new Errors_1.ValidationError('X cannot be empty');
        }
        validation_1.validateMatrix2D(X);
        var matrix = tf.tensor2d(X);
        var _a = __read(matrix.shape, 2), nSamples = _a[0], nFeatures = _a[1];
        var indexCombination = this.indexCombination(nFeatures, this.degree);
        var nOutputFeatures = indexCombination.length;
        // Polynomial feature extraction loop begins
        var tfOnes = tf.ones([nSamples, nOutputFeatures]);
        var result = tensors_1.reshape(Array.from(tfOnes.dataSync()), tfOnes.shape);
        var rowRange = _.range(0, X.length);
        for (var i = 0; i < indexCombination.length; i++) {
            var c = indexCombination[i];
            var colsRange = Array.isArray(c) ? c : [c];
            // Retrieves column values from X using the index of the indexCombination in the loop
            var srcColValues = c !== null ? MathExtra_1.default.subset(X, rowRange, colsRange) : [];
            var xc = null;
            if (srcColValues.length === 0) {
                xc = _.fill(rowRange.slice(), 1);
            }
            else {
                xc = tf
                    .tensor2d(srcColValues)
                    .prod(1)
                    .dataSync();
            }
            result = MathExtra_1.default.subset(result, rowRange, [i], xc);
        }
        return result;
    };
    /**
     * Creates a combination of index according to nFeautres and degree
     * @param nFeatures
     * @param degree
     */
    PolynomialFeatures.prototype.indexCombination = function (nFeatures, degree) {
        var range = _.range(0, degree + 1);
        var combs = range.map(function (i) {
            return permutations_1.combinationsWithReplacement(_.range(nFeatures), i);
        });
        return combs.reduce(function (sum, cur) {
            return sum.concat(cur);
        }, []);
    };
    return PolynomialFeatures;
}());
exports.PolynomialFeatures = PolynomialFeatures;
/**
 * Data normalization is a process of scaling dataset based on Vector Space Model, and by default, it uses L2 normalization.
 * At a higher level, the chief difference between the L1 and the L2 terms is that the L2 term is proportional
 * to the square of the  β values, while the L1 norm is proportional the absolute value of the values in  β .
 *
 * @example
 * import { normalize } from 'machinelearn/preprocessing';
 *
 * const result = normalize([
 *   [1, -1, 2],
 *   [2, 0, 0],
 *   [0, 1, -1],
 * ], { norm: 'l2' });
 * console.log(result);
 * // [ [ 0.4082482904638631, -0.4082482904638631, 0.8164965809277261 ],
 * // [ 1, 0, 0 ],
 * // [ 0, 0.7071067811865475, -0.7071067811865475 ] ]
 *
 * @param X - The data to normalize
 * @param norm - The norm to use to normalize each non zero sample; can be either 'l1' or 'l2'
 * @return number[][]
 */
function normalize(X, _a) {
    if (X === void 0) { X = null; }
    var _b = (_a === void 0 ? {
        norm: 'l2',
    } : _a).norm, norm = _b === void 0 ? 'l2' : _b;
    if (Array.isArray(X) && X.length === 0) {
        throw new Errors_1.ValidationError('X cannot be empty');
    }
    validation_1.validateMatrix2D(X);
    var normalizedMatrix = [];
    for (var i = 0; i < X.length; i++) {
        var row = X[i];
        // Adding a placeholder array
        normalizedMatrix.push([]);
        // Getting the row's square root
        var proportion = 0; // note: any because math.pow return MathType
        // Normalization proportion value
        if (norm === 'l1') {
            proportion = row.reduce(function (accum, r) { return accum + Math.abs(r); }, 0);
        }
        else if (norm === 'l2') {
            proportion = row.reduce(function (accum, r) { return accum + Math.pow(r, 2); }, 0);
            proportion = Math.sqrt(proportion);
        }
        else {
            throw new Errors_1.ValidationError(norm + " is not a recognised normalization method");
        }
        // Finally applying a cubic root to the total value
        for (var k = 0; k < row.length; k++) {
            var value = row[k] / proportion;
            normalizedMatrix[i].push(value);
        }
    }
    return normalizedMatrix;
}
exports.normalize = normalize;
//# sourceMappingURL=data:application/json;base64,{"version":3,"file":"data.js","sourceRoot":"","sources":["../../../src/lib/preprocessing/data.ts"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA,mDAAuC;AACvC,wCAA4B;AAE5B,0CAAiG;AACjG,iEAAsC;AACtC,sDAAoE;AACpE,4CAAuD;AACvD,kDAAyE;AAoCzE;;;;;;;;;;;GAWG;AACH,SAAgB,iBAAiB,CAAC,CAA8B,EAAE,KAAmB;IAAnD,kBAAA,EAAA,QAA8B;IAAE,sBAAA,EAAA,WAAmB;IACnF,IAAI,KAAK,CAAC,OAAO,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,MAAM,KAAK,CAAC,EAAE;QACtC,MAAM,IAAI,SAAS,CAAC,mBAAmB,CAAC,CAAC;KAC1C;IACD,6BAAgB,CAAC,CAAC,CAAC,CAAC;IACpB,IAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAc,CAAC;IACtC,IAAA,6BAA0B,EAAzB,gBAAyB,CAAC;IACjC,IAAM,IAAI,GAAG,EAAE,CAAC,IAAI,CAAC,CAAC,QAAQ,EAAE,CAAC,CAAC,CAAc,CAAC;IACjD,IAAM,MAAM,GAAG,EAAE,CAAC,MAAM,CAAC,KAAK,CAAc,CAAC;IAC7C,IAAM,aAAa,GAAG,EAAE,CAAC,GAAG,CAAC,IAAI,EAAE,MAAM,CAAC,CAAC;IAC3C,IAAM,QAAQ,GAAG,EAAE,CAAC,MAAM,CAAC,CAAC,aAAa,EAAE,OAAO,CAAC,EAAE,CAAC,CAAC,CAAC;IACxD,OAAO,iBAAO,CAAC,KAAK,CAAC,IAAI,CAAC,QAAQ,CAAC,QAAQ,EAAE,CAAC,EAAE,QAAQ,CAAC,KAAK,CAAe,CAAC;AAChF,CAAC;AAZD,8CAYC;AAED;;;;;;;;;;;;;;;;;;;;;;;;;;;GA2BG;AACH;IAAA;QAwLE;;;;;WAKG;QACK,iBAAY,GAAG,UAAC,GAAG,EAAE,IAAY;YACvC,IAAM,UAAU,GAAG,CAAC,CAAC,GAAG,CAAC,GAAG,EAAE,UAAC,CAAS,IAAK,OAAA,IAAI,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,EAAE,CAAC,CAAC,EAArB,CAAqB,CAAC,CAAC;YACpE,OAAO,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,UAAU,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,GAAG,CAAC,CAAC,EAAE,GAAG,CAAC,CAAC;QAC7D,CAAC,CAAC;IA4EJ,CAAC;IA5QC;;;;;OAKG;IACI,8BAAM,GAAb,UACE,IAAW,EACX,EAeC;QAjBH,iBA8EC;QA7EC,qBAAA,EAAA,WAAW;YACX;;;cAeC;QAdC;;WAEG;QACH,gBAAe;QAHf;;WAEG;QACH,oCAAe;QACf;;WAEG;QACH,iBAAgB;QAHhB;;WAEG;QACH,qCAAgB;QAkBlB,IAAM,QAAQ,GAAG,EAAE,CAAC;QAEpB,4EAA4E;QAC5E,IAAM,SAAS,GAAG,QAAQ,CAAC,CAAC,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC;QACxD,cAAc;QACd,IAAI,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE;YACpB,MAAM,wBAAe,CAAC,uBAAuB,CAAC,CAAC;SAChD;QACD,YAAY;QACZ,CAAC,CAAC,OAAO,CAAC,SAAS,EAAE,UAAC,OAAO;YAC3B,0EAA0E;YAC1E,IAAI,CAAC,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,OAAO,CAAC,EAAE;gBAC5B,wCAAwC;gBACxC,MAAM,IAAI,mCAA0B,CAAC,iBAAe,OAAO,eAAY,CAAC,CAAC;aAC1E;QACH,CAAC,CAAC,CAAC;QAEH,aAAa;QACb,CAAC,CAAC,OAAO,CAAC,SAAS,EAAE,UAAC,QAAQ;YAC5B,0EAA0E;YAC1E,IAAI,CAAC,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,QAAQ,CAAC,EAAE;gBAC7B,uCAAuC;gBACvC,MAAM,IAAI,mCAA0B,CAAC,iBAAe,QAAQ,iBAAc,CAAC,CAAC;aAC7E;QACH,CAAC,CAAC,CAAC;QAEH,mDAAmD;QACnD,0GAA0G;QAC1G,IAAM,SAAS,GAAG,UAAC,IAA0B;YAC3C,OAAA,CAAC,CAAC,GAAG,OAAL,CAAC,WACI,CAAC,CAAC,GAAG,CAAC,IAAI,EAAE,UAAC,GAAW;gBACzB,IAAM,YAAY,GAAG,KAAI,CAAC,gBAAgB,CAAC,GAAG,EAAE,IAAI,CAAC,CAAC;gBACtD,IAAM,OAAO,GAAG,CAAC,CAAC,GAAG,CAAC,YAAY,EAAE,SAAS,CAAC,CAAC;gBAC/C,IAAM,MAAM,GAAG,CAAC,CAAC,GAAG,CAAC,YAAY,EAAE,QAAQ,CAAC,CAAC;gBAC7C,IAAI,OAAO,IAAI,MAAM,EAAE;oBACrB,kDAAkD;oBAClD,QAAQ,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;oBACtB,OAAO,OAAO,CAAC;iBAChB;gBACD,sCAAsC;gBACtC,OAAO,YAAY,CAAC;YACtB,CAAC,CAAC;QAZJ,CAaC,CAAC;QACJ,IAAM,QAAQ,GAAG,SAAS,CAAC,SAAS,CAAC,CAAC;QACtC,IAAM,MAAM,GAAG,SAAS,CAAC,SAAS,CAAC,CAAC;QACpC,OAAO;YACL,qFAAqF;YACrF,IAAI,EAAE,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,QAAQ,EAAE,MAAM,CAAC,EAAE,CAAC,CAAC,WAAW,CAAC;YACnD,QAAQ,UAAA;SACT,CAAC;IACJ,CAAC;IAED;;OAEG;IACI,8BAAM,GAAb,UAAc,OAAO,EAAE,QAAQ;QAA/B,iBAEC;QADC,OAAO,CAAC,CAAC,GAAG,CAAC,OAAO,EAAE,UAAC,GAAG,IAAK,OAAA,KAAI,CAAC,SAAS,CAAC,GAAG,EAAE,QAAQ,CAAC,EAA7B,CAA6B,CAAC,CAAC;IAChE,CAAC;IAED;;;;;OAKG;IACK,iCAAS,GAAjB,UAAkB,GAAG,EAAE,QAAQ;QAC7B,IAAI,CAAC,GAAG,CAAC,CAAC;QACV,IAAI,gBAAgB,GAAG,CAAC,CAAC;QACzB,IAAM,MAAM,GAAG,EAAE,CAAC;QAElB,IAAM,SAAS,GAAG,UAAC,CAAC,EAAE,EAAE,EAAE,OAAO;YAC/B,IAAM,IAAI,GAAG,CAAC,CAAC,KAAK,CAAC,EAAE,EAAE,EAAE,GAAG,OAAO,CAAC,MAAM,CAAC,CAAC;YAC9C,OAAO,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,OAAO,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC,CAAC;QACjD,CAAC,CAAC;QAEF,IAAM,UAAU,GAAG,UAAC,CAAC,EAAE,EAAE,IAAc,OAAA,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,EAAP,CAAO,CAAC;QAE/C,IAAM,UAAU,GAAG,UAAC,CAAC,EAAE,EAAE,EAAE,OAAO;YAChC,OAAO,OAAO,CAAC,GAAG,GAAG,CAAC,CAAC,EAAE,CAAC,GAAG,OAAO,CAAC,IAAI,CAAC;QAC5C,CAAC,CAAC;QAEF,OAAO,CAAC,GAAG,GAAG,CAAC,MAAM,EAAE;YACrB,IAAM,OAAO,GAAG,QAAQ,CAAC,gBAAgB,EAAE,CAAC,CAAC;YAC7C,IAAI,OAAO,CAAC,IAAI,KAAK,QAAQ,EAAE;gBAC7B,MAAM,CAAC,OAAO,CAAC,GAAG,CAAC,GAAG,SAAS,CAAC,GAAG,EAAE,CAAC,EAAE,OAAO,CAAC,CAAC;aAClD;iBAAM,IAAI,OAAO,CAAC,IAAI,KAAK,QAAQ,EAAE;gBACpC,MAAM,CAAC,OAAO,CAAC,GAAG,CAAC,GAAG,UAAU,CAAC,GAAG,EAAE,CAAC,EAAE,OAAO,CAAC,CAAC;aACnD;iBAAM,IAAI,OAAO,CAAC,IAAI,KAAK,SAAS,EAAE;gBACrC,MAAM,CAAC,OAAO,CAAC,GAAG,CAAC,GAAG,UAAU,CAAC,GAAG,EAAE,CAAC,CAAC,CAAC;aAC1C;iBAAM;gBACL,MAAM,CAAC,OAAO,CAAC,GAAG,CAAC,GAAG,GAAG,CAAC,CAAC,CAAC,CAAC;aAC9B;YACD,mDAAmD;YACnD,CAAC,IAAI,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;SAC1C;QACD,OAAO,MAAM,CAAC;IAChB,CAAC;IAED;;;;;;;;;;OAUG;IACK,wCAAgB,GAAxB,UAAyB,GAAG,EAAE,IAAI;QAChC,IAAM,IAAI,GAAG,OAAO,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;QACjC,IAAM,MAAM,GAAG,CAAC,CAAC,GAAG,CAAC,IAAI,EAAE,GAAG,CAAC,CAAC;QAChC,QAAQ,IAAI,EAAE;YACZ,KAAK,QAAQ,CAAC,CAAC;gBACb,IAAM,MAAM,GAAG,IAAI,CAAC,iBAAiB,CAAC,IAAI,EAAE,GAAG,EAAE,MAAM,CAAC,CAAC;gBACzD,OAAO;oBACL,MAAM,EAAE,MAAM,CAAC,MAAM;oBACrB,OAAO,EAAE,MAAM,CAAC,OAAO;iBACxB,CAAC;aACH;YAED,KAAK,QAAQ,CAAC,CAAC;gBACb,wCAAwC;gBACxC,gCAAgC;gBAChC,0CAA0C;gBAC1C,IAAM,MAAM,GAAG,IAAI,CAAC,iBAAiB,CAAC,IAAI,EAAE,GAAG,EAAE,MAAM,CAAC,CAAC;gBAEzD,OAAO;oBACL,MAAM,EAAE,MAAM,CAAC,MAAM;oBACrB,OAAO,EAAE,MAAM,CAAC,OAAO;iBACxB,CAAC;aACH;YAED,KAAK,SAAS,CAAC,CAAC;gBACd,YAAY;gBACZ,aAAa;gBACb,IAAM,MAAM,GAAG,IAAI,CAAC,kBAAkB,CAAC,IAAI,EAAE,GAAG,EAAE,MAAM,CAAC,CAAC;gBAE1D,OAAO;oBACL,MAAM,EAAE,MAAM,CAAC,MAAM;oBACrB,OAAO,EAAE,MAAM,CAAC,OAAO;iBACxB,CAAC;aACH;YAED;gBACE,OAAO,MAAM,CAAC;SACjB;IACH,CAAC;IAaD;;;;;;;OAOG;IACK,yCAAiB,GAAzB,UAA0B,IAAI,EAAE,GAAG,EAAE,MAAM;QACzC,IAAM,IAAI,GAAW,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;QACpC,IAAM,GAAG,GAAG,IAAI,CAAC,YAAY,CAAC,MAAM,EAAE,IAAI,CAAC,CAAC;QAC5C,OAAO;YACL,MAAM,EAAE,EAAE,IAAI,MAAA,EAAE,IAAI,MAAA,EAAE,GAAG,KAAA,EAAE,GAAG,KAAA,EAAE;YAChC,OAAO,EAAE,CAAC,CAAC,GAAG,CAAC,MAAM,EAAE,UAAC,KAAa,IAAK,OAAA,CAAC,KAAK,GAAG,IAAI,CAAC,GAAG,GAAG,EAApB,CAAoB,CAAC;SAChE,CAAC;IACJ,CAAC;IAED;;;;;;;;;;;OAWG;IACK,0CAAkB,GAA1B,UAA2B,IAAI,EAAE,GAAG,EAAE,MAAM;QAC1C,OAAO;YACL,MAAM,EAAE,EAAE,IAAI,MAAA,EAAE,GAAG,KAAA,EAAE;YACrB,OAAO,EAAE,CAAC,CAAC,GAAG,CAAC,MAAM,EAAE,UAAC,KAAK,IAAK,OAAA,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,EAAf,CAAe,CAAC;SACnD,CAAC;IACJ,CAAC;IAED;;;;;;;;;;;;;;OAcG;IACK,yCAAiB,GAAzB,UAA0B,IAAI,EAAE,GAAG,EAAE,MAAM;QACzC,IAAM,MAAM,GAAG,EAAE,CAAC;QAClB,IAAI,CAAC,GAAG,CAAC,CAAC;QAEV,IAAM,WAAW,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC,EAAE,UAAC,KAAa;YACtD,CAAC,CAAC,GAAG,CAAC,MAAM,EAAE,KAAK,EAAE,CAAC,EAAE,CAAC,CAAC;YAC1B,OAAO,KAAK,CAAC;QACf,CAAC,CAAC,CAAC;QAEH,IAAM,OAAO,GAAG,CAAC,CAAC,GAAG,CAAC,MAAM,EAAE,UAAC,KAAa;YAC1C,OAAA,CAAC,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,GAAG,CAAC,UAAC,GAAG,IAAK,OAAA,CAAC,CAAC,CAAC,GAAG,CAAC,MAAM,EAAE,KAAK,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,EAAtC,CAAsC,CAAC;QAAlE,CAAkE,CACnE,CAAC;QAEF,OAAO;YACL,MAAM,EAAE;gBACN,GAAG,KAAA;gBACH,WAAW,aAAA;gBACX,MAAM,EAAE,OAAO,CAAC,CAAC,CAAC,CAAC,MAAM;gBACzB,IAAI,MAAA;aACL;YACD,OAAO,SAAA;SACR,CAAC;IACJ,CAAC;IACH,oBAAC;AAAD,CAAC,AA7QD,IA6QC;AA7QY,sCAAa;AA+Q1B;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;GAgCG;AACH;IAUE;;OAEG;IACH,sBACE,EAMC;YALC;;4BAAqB,EAArB,0CAAqB;QAOvB,IAAI,CAAC,YAAY,GAAG,YAAY,CAAC;IACnC,CAAC;IAED;;;OAGG;IACI,0BAAG,GAAV,UAAW,CAAqD;QAArD,kBAAA,EAAA,QAAqD;QAC9D,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE;YACrB,MAAM,IAAI,wBAAe,CAAC,+CAA+C,CAAC,CAAC;SAC5E;QACD,IAAI,MAAM,GAAG,EAAE,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC;QAC1B,IAAI,MAAM,GAAG,EAAE,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC;QAC1B,IAAM,MAAM,GAAG,oBAAU,CAAC,CAAC,CAAC,CAAC;QAC7B,0BAA0B;QAC1B,IAAI,MAAM,CAAC,MAAM,KAAK,CAAC,IAAI,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,EAAE;YAC1C,MAAM,IAAI,wBAAe,CAAC,gCAAgC,CAAC,CAAC;SAC7D;aAAM,IAAI,MAAM,CAAC,MAAM,KAAK,CAAC,EAAE;YAC9B,MAAM,GAAG,EAAE,CAAC,GAAG,CAAC,MAAmB,EAAE,CAAC,CAAC,CAAC;YACxC,MAAM,GAAG,EAAE,CAAC,GAAG,CAAC,MAAmB,EAAE,CAAC,CAAC,CAAC;SACzC;QACD,IAAI,CAAC,OAAO,GAAG,EAAE,CAAC,GAAG,CAAC,MAAmB,CAAC,CAAC,QAAQ,EAAE,CAAC,CAAC,CAAC,CAAC;QACzD,IAAI,CAAC,OAAO,GAAG,EAAE,CAAC,GAAG,CAAC,MAAmB,CAAC,CAAC,QAAQ,EAAE,CAAC,CAAC,CAAC,CAAC;QACzD,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC;QACvC,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC;QACvC,IAAI,CAAC,SAAS,GAAG,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,OAAO,CAAC;QAC7C,qDAAqD;QACrD,IAAI,CAAC,KAAK,GAAG,CAAC,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,UAAU,CAAC,GAAG,IAAI,CAAC,SAAS,CAAC;QAClE,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,KAAK,CAAC;IAC7D,CAAC;IAED;;;OAGG;IACI,oCAAa,GAApB,UAAqB,CAA8C;QACjE,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QACZ,OAAO,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC;IAC3B,CAAC;IAED;;;OAGG;IACI,gCAAS,GAAhB,UAAiB,CAAqD;QAAtE,iBAcC;QAdgB,kBAAA,EAAA,QAAqD;QACpE,6BAA6B;QAC7B,IAAM,gBAAgB,GAAG,UAAC,EAAE;YAC1B,IAAM,EAAE,GAAG,EAAE,CAAC,GAAG,CAAC,UAAC,CAAC,IAAK,OAAA,CAAC,GAAG,KAAI,CAAC,KAAK,EAAd,CAAc,CAAC,CAAC;YACzC,OAAO,EAAE,CAAC,GAAG,CAAC,UAAC,CAAC,IAAK,OAAA,CAAC,GAAG,KAAI,CAAC,OAAO,EAAhB,CAAgB,CAAC,CAAC;QACzC,CAAC,CAAC;QACF,IAAM,MAAM,GAAG,oBAAU,CAAC,CAAC,CAAC,CAAC;QAC7B,IAAI,MAAM,CAAC,MAAM,KAAK,CAAC,EAAE;YACvB,OAAQ,CAAgB,CAAC,GAAG,CAAC,UAAC,CAAC,IAAK,OAAA,gBAAgB,CAAC,CAAC,CAAC,EAAnB,CAAmB,CAAC,CAAC;SAC1D;aAAM,IAAI,MAAM,CAAC,MAAM,KAAK,CAAC,EAAE;YAC9B,OAAO,gBAAgB,CAAC,CAAC,CAAC,CAAC;SAC5B;aAAM;YACL,MAAM,IAAI,SAAS,CAAC,qBAAmB,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC,2BAAwB,CAAC,CAAC;SACxF;IACH,CAAC;IAED;;;OAGG;IACI,wCAAiB,GAAxB,UAAyB,CAA8B;QAAvD,iBAIC;QAJwB,kBAAA,EAAA,QAA8B;QACrD,6BAAgB,CAAC,CAAC,CAAC,CAAC;QACpB,IAAM,EAAE,GAAG,CAAC,CAAC,GAAG,CAAC,UAAC,CAAC,IAAK,OAAA,CAAC,GAAG,KAAI,CAAC,OAAO,EAAhB,CAAgB,CAAC,CAAC;QAC1C,OAAO,EAAE,CAAC,GAAG,CAAC,UAAC,CAAC,IAAK,OAAA,CAAC,GAAG,KAAI,CAAC,KAAK,EAAd,CAAc,CAAC,CAAC;IACvC,CAAC;IACH,mBAAC;AAAD,CAAC,AA3FD,IA2FC;AA3FY,oCAAY;AA6FzB;;;;;;;;;;;;;;;GAeG;AACH;IAIE;;;;OAIG;IACH,mBACE,EAYC;YAZD;;;;cAYC;QAXC,kCAAkC;QAClC,YAAW;QADX,kCAAkC;QAClC,gCAAW,EACX,iBAAa,EAAb,kCAAa;QAWf,IAAI,CAAC,SAAS,GAAG,SAAS,CAAC;QAC3B,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC;IACnB,CAAC;IAED;;;OAGG;IACI,uBAAG,GAAV,UAAW,CAA8B;QAA9B,kBAAA,EAAA,QAA8B;QACvC,IAAI,KAAK,CAAC,OAAO,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,MAAM,KAAK,CAAC,EAAE;YACtC,MAAM,IAAI,wBAAe,CAAC,0CAA0C,CAAC,CAAC;SACvE;QACD,6BAAgB,CAAC,CAAC,CAAC,CAAC;QACpB,OAAO,CAAC,IAAI,CAAC,qDAAqD,CAAC,CAAC;IACtE,CAAC;IAED;;;;;;;;;;OAUG;IACI,6BAAS,GAAhB,UAAiB,CAA8B;QAA9B,kBAAA,EAAA,QAA8B;QAC7C,IAAM,EAAE,GAAG,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACtC,IAAI,KAAK,CAAC,OAAO,CAAC,EAAE,CAAC,IAAI,EAAE,CAAC,MAAM,KAAK,CAAC,EAAE;YACxC,MAAM,IAAI,wBAAe,CAAC,0CAA0C,CAAC,CAAC;SACvE;QACD,6BAAgB,CAAC,EAAE,CAAC,CAAC;QACrB,KAAK,IAAI,GAAG,GAAG,CAAC,EAAE,GAAG,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,GAAG,EAAE,EAAE;YACxC,IAAM,QAAQ,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,MAAI,GAAG,MAAG,CAAC,CAAC;YACtC,KAAK,IAAI,MAAM,GAAG,CAAC,EAAE,MAAM,GAAG,CAAC,CAAC,IAAI,CAAC,QAAQ,CAAC,EAAE,MAAM,EAAE,EAAE;gBACxD,IAAM,IAAI,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,MAAI,GAAG,UAAK,MAAM,MAAG,CAAC,CAAC;gBAC7C,+CAA+C;gBAC/C,IAAI,CAAC,CAAC,CAAC,QAAQ,CAAC,IAAI,CAAC,EAAE;oBACrB,MAAM,IAAI,KAAK,CAAC,WAAS,IAAI,qBAAkB,CAAC,CAAC;iBAClD;gBACD,+BAA+B;gBAC/B,EAAE,CAAC,GAAG,CAAC,CAAC,MAAM,CAAC,GAAG,IAAI,IAAI,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;aAClD;SACF;QACD,OAAO,EAAE,CAAC;IACZ,CAAC;IACH,gBAAC;AAAD,CAAC,AAvED,IAuEC;AAvEY,8BAAS;AAyEtB;;;;;;;;;;;;;;;;;GAiBG;AACH;IAGE;;;OAGG;IACH,4BACE,EAMC;YALC;;sBAAU,EAAV,+BAAU;QAOZ,mCAAmC;QACnC,IAAI,CAAC,MAAM,CAAC,SAAS,CAAC,MAAM,CAAC,EAAE;YAC7B,MAAM,IAAI,0BAAiB,CAAC,yBAAyB,CAAC,CAAC;SACxD;QACD,IAAI,CAAC,MAAM,GAAG,MAAM,CAAC;IACvB,CAAC;IAED;;;OAGG;IACI,sCAAS,GAAhB,UAAiB,CAA8B;QAA9B,kBAAA,EAAA,QAA8B;QAC7C,IAAI,KAAK,CAAC,OAAO,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,MAAM,KAAK,CAAC,EAAE;YACtC,MAAM,IAAI,wBAAe,CAAC,mBAAmB,CAAC,CAAC;SAChD;QACD,6BAAgB,CAAC,CAAC,CAAC,CAAC;QACpB,IAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC;QACxB,IAAA,4BAAoC,EAAnC,gBAAQ,EAAE,iBAAyB,CAAC;QAC3C,IAAM,gBAAgB,GAAG,IAAI,CAAC,gBAAgB,CAAC,SAAS,EAAE,IAAI,CAAC,MAAM,CAAC,CAAC;QACvE,IAAM,eAAe,GAAG,gBAAgB,CAAC,MAAM,CAAC;QAEhD,4CAA4C;QAC5C,IAAM,MAAM,GAAG,EAAE,CAAC,IAAI,CAAC,CAAC,QAAQ,EAAE,eAAe,CAAC,CAAC,CAAC;QACpD,IAAI,MAAM,GAAG,iBAAO,CAAC,KAAK,CAAC,IAAI,CAAC,MAAM,CAAC,QAAQ,EAAE,CAAC,EAAE,MAAM,CAAC,KAAK,CAAC,CAAC;QAClE,IAAM,QAAQ,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,MAAM,CAAC,CAAC;QACtC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,gBAAgB,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;YAChD,IAAM,CAAC,GAAG,gBAAgB,CAAC,CAAC,CAAC,CAAC;YAC9B,IAAM,SAAS,GAAG,KAAK,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;YAC7C,qFAAqF;YACrF,IAAM,YAAY,GAAQ,CAAC,KAAK,IAAI,CAAC,CAAC,CAAC,mBAAI,CAAC,MAAM,CAAC,CAAC,EAAE,QAAQ,EAAE,SAAS,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC;YAChF,IAAI,EAAE,GAAG,IAAI,CAAC;YACd,IAAI,YAAY,CAAC,MAAM,KAAK,CAAC,EAAE;gBAC7B,EAAE,GAAG,CAAC,CAAC,IAAI,CAAC,QAAQ,CAAC,KAAK,EAAE,EAAE,CAAC,CAAC,CAAC;aAClC;iBAAM;gBACL,EAAE,GAAG,EAAE;qBACJ,QAAQ,CAAC,YAAY,CAAC;qBACtB,IAAI,CAAC,CAAC,CAAC;qBACP,QAAQ,EAAE,CAAC;aACf;YACD,MAAM,GAAG,mBAAI,CAAC,MAAM,CAAC,MAAM,EAAE,QAAQ,EAAE,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC;SACjD;QACD,OAAO,MAAoB,CAAC;IAC9B,CAAC;IAED;;;;OAIG;IACK,6CAAgB,GAAxB,UAAyB,SAAS,EAAE,MAAM;QACxC,IAAM,KAAK,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,EAAE,MAAM,GAAG,CAAC,CAAC,CAAC;QACrC,IAAM,KAAK,GAAG,KAAK,CAAC,GAAG,CAAC,UAAC,CAAC;YACxB,OAAO,0CAA2B,CAAC,CAAC,CAAC,KAAK,CAAC,SAAS,CAAC,EAAE,CAAC,CAAC,CAAC;QAC5D,CAAC,CAAC,CAAC;QACH,OAAO,KAAK,CAAC,MAAM,CAAC,UAAC,GAAG,EAAE,GAAG;YAC3B,OAAO,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC;QACzB,CAAC,EAAE,EAAE,CAAC,CAAC;IACT,CAAC;IACH,yBAAC;AAAD,CAAC,AA1ED,IA0EC;AA1EY,gDAAkB;AA4E/B;;;;;;;;;;;;;;;;;;;;;GAqBG;AACH,SAAgB,SAAS,CACvB,CAA8B,EAC9B,EAMC;IAPD,kBAAA,EAAA,QAA8B;QAE5B;;gBAAW,EAAX,gCAAW;IAOb,IAAI,KAAK,CAAC,OAAO,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,MAAM,KAAK,CAAC,EAAE;QACtC,MAAM,IAAI,wBAAe,CAAC,mBAAmB,CAAC,CAAC;KAChD;IACD,6BAAgB,CAAC,CAAC,CAAC,CAAC;IACpB,IAAM,gBAAgB,GAAG,EAAE,CAAC;IAC5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;QACjC,IAAM,GAAG,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC;QAEjB,6BAA6B;QAC7B,gBAAgB,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;QAE1B,gCAAgC;QAChC,IAAI,UAAU,GAAQ,CAAC,CAAC,CAAC,6CAA6C;QAEtE,iCAAiC;QACjC,IAAI,IAAI,KAAK,IAAI,EAAE;YACjB,UAAU,GAAG,GAAG,CAAC,MAAM,CAAC,UAAC,KAAU,EAAE,CAAC,IAAK,OAAA,KAAK,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,EAAnB,CAAmB,EAAE,CAAC,CAAC,CAAC;SACpE;aAAM,IAAI,IAAI,KAAK,IAAI,EAAE;YACxB,UAAU,GAAG,GAAG,CAAC,MAAM,CAAC,UAAC,KAAU,EAAE,CAAC,IAAK,OAAA,KAAK,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,EAAtB,CAAsB,EAAE,CAAC,CAAC,CAAC;YACtE,UAAU,GAAG,IAAI,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC;SACpC;aAAM;YACL,MAAM,IAAI,wBAAe,CAAI,IAAI,8CAA2C,CAAC,CAAC;SAC/E;QAED,mDAAmD;QACnD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;YACnC,IAAM,KAAK,GAAG,GAAG,CAAC,CAAC,CAAC,GAAG,UAAU,CAAC;YAClC,gBAAgB,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;SACjC;KACF;IACD,OAAO,gBAAgB,CAAC;AAC1B,CAAC;AAzCD,8BAyCC"}